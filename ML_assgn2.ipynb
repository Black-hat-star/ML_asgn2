{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1d2a3980-2b53-47cb-9042-b8c655b1c680",
   "metadata": {},
   "source": [
    "1)overfitting occurs when the ml model performs tooo well on train data nad performs worst on test data whereas underfitting occurs when the ml model perform not so well in train data and also not so well in test data .Overfitting can be mitigated by Increase Data: Provide more training data to the model, as more data can help the model generalize better. Feature Selection: Select relevant features and eliminate irrelevant ones to reduce the risk of overfitting.\n",
    "\n",
    "Underfitting can be mitigted by Feature Engineering: Introduce more relevant features that better represent the relationships within the data.\n",
    "Optimize Hyperparameters: Fine-tune hyperparameters like learning rate, batch size, and others to find the right balance between model complexity and generalization."
   ]
  },
  {
   "cell_type": "raw",
   "id": "05297312-ac66-4271-b90b-27f0c0729dcc",
   "metadata": {},
   "source": [
    "2)overfitting can be reduced by \n",
    "Cross-Validation: Use techniques like k-fold cross-validation to assess model performance on multiple subsets of the data.\n",
    "Regularization: Introduce regularization terms in the model to penalize overly complex models and discourage the learning of noise.\n",
    "Feature Selection: Select relevant features and eliminate irrelevant ones to reduce the risk of overfitting.\n",
    "Increase Data: Provide more training data to the model, as more data can help the model generalize better."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d655d2f1-8ec3-4d2d-b0c3-b304b040e25e",
   "metadata": {},
   "source": [
    "3)underfitting occurs when the ml model perform not so well in train data also not  do well in test data\n",
    "Model Complexity:\n",
    "\n",
    "Simple Models: If you choose a model that is too basic or has low complexity, it may not have the capacity to learn from the complexity present in the data.\n",
    "Insufficient Features:\n",
    "\n",
    "Feature Poverty: When the features provided to the model are not sufficient to represent the underlying relationships in the data, the model may struggle to make accurate predictions.\n",
    "Over-regularization:\n",
    "\n",
    "Strong Regularization: Regularization techniques, which are used to prevent overfitting, can also lead to underfitting if they are too aggressive. High regularization penalizes the model for complexity, and in extreme cases, it might make the model too simple.\n",
    "Insufficient Training:\n",
    "\n",
    "Limited Training Data: If the training dataset is too small, the model may not be exposed to enough examples to capture the underlying patterns effectively."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f28fd77d-756a-4a5b-adcb-dafa0efd5c37",
   "metadata": {},
   "source": [
    "5)Cross-Validation:\n",
    "Overfitting: Cross-validation involves training the model on different subsets of the data. If the model performs well on the training sets but poorly on the validation sets, it might be overfitting.\n",
    "Underfitting: Consistently poor performance across all folds may indicate underfitting.\n",
    "\n",
    "Evaluation Metrics:\n",
    "Overfitting: Compare performance metrics (e.g., accuracy, precision, recall) on the training and validation sets. Overfitting may be present if the model performs significantly better on the training set.\n",
    "Underfitting: Poor performance on both training and validation sets may indicate underfitting\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb04736b-ef9c-4146-a156-d1acb7f66142",
   "metadata": {},
   "source": [
    "6)variance-tendency of the machines to make random errors\n",
    "bias-tendency of the machine to make systematic errors\n",
    "in high variance model model performs well on train data but low on validation data\n",
    "Bias is an error introduced by approximating a real-world problem, which may be complex, by a simplified model. A model with high bias is overly simplistic and fails to capture the underlying patterns in the data. As a result, it performs poorly not only on the training data but also on new, unseen data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "00a2d3de-b30c-4bd3-aaa3-437f2183ea77",
   "metadata": {},
   "source": [
    "4)bias is basically the tendency of the models to make systematic erros\n",
    "whereas in variance is the tendency of the mdels to make random erros\n",
    "Underfitting: A model with high bias tends to underfit the training data, performing poorly on both the training set and new, unseen data.\n",
    "Consistent Errors: The model consistently makes errors, and its predictions may be systematically off-target.\n",
    "\n",
    "Effect on Performance:\n",
    "Overfitting: A model with high variance tends to overfit the training data, performing well on the training set but poorly on new, unseen data.\n",
    "Inconsistent Predictions: The model may produce different predictions for slightly different training datasets."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1cdcf0e-7dde-4e2a-909a-442ee74cd320",
   "metadata": {},
   "source": [
    "7) regularization is a technique used to prevent overfitting and improve the generalization of a model.\n",
    "i-L2 regularization in which the cost function is added with a hyperparamtre times slope square\n",
    "ii-L1 regularization in which the cost function is added with hyperparamtre times mod of slope value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf2a9e-80f6-4585-90f5-da1c396b6564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
